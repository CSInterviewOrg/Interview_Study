**가상화란 무엇이며, 운영 체제에서 왜 중요한가요?**

- 가상화란 컴퓨팅의 실제 물리 자원인 CPU, Memory, Disk..를 가상 자원 또는 논리적인 자원인 Process, Virtual Memory, File으로 추상화 시키는 것입니다.
- 이러한 가상화가 중요한 이유는 디테일하고 불필요한 정보를 감추고 필요한 정보에만 집중하여 시스템이 보다 효율적이고 정확하게 작동할 수 있게끔 하기 위함입니다. → 예를 들어서 실제로 CPU는 한개이지만 여러 개의 가상 CPU(Process)로 분할하여 여러 프로그램을 동시에 실행 시킬 수 있는 것이 하나의 예입니다.
    - Program: 실행 중이 아니며 디스크에 존재하는 것
    - Process: CPU에 스케줄링 되는(CPU 스케줄링에 대기하는 것도 포함하는) 프로그램
    - Job: CPU에 스케줄링 되고 있는 프로세스
- 그래서 운영체제는 이러한 물리 자원 또는 하드웨어 자원을 가상화(추상화) 시키며 추상화된 자원들을 관리하는 Resource Manager입니다.
- 참고: https://pawoo0211.tistory.com/61

**운영 체제가 CPU, 메모리, 디스크를 가상화한 것은 무엇인가요?**

- CPU → 프로세스
- 메모리 → Virtual Memory
- 디스크 → File System

**운영체제에서 커널이란 무엇이며 시스템 콜에 대해서 설명해주세요**

- 커널이란 실질적으로 하드웨어 자원에 접근하거나 하드웨어 자원을 관리하는 운영체제의 핵심 부분입니다.
    - 운영체제와 커널의 차이점은 운영체제에 포함되는 많은 요소 중 핵심 요소가 커널입니다.
- 커널 모드: CPU가 특권 명령어를 실행할 수 있는 모드로 실질적으로 하드웨어 자원에 접근할 수 있는 상태입니다. 커널 모드가 아닐 경우 하드웨어 자원에 접근할 수 없습니다.
- 유저 모드: 사용자 Application이 실행 되는 모드로 하드웨어 자원에 대해서 직접적으로 접근할 수 없는 모드입니다. 그렇기에 유저 모드에서 하드웨어 자원에 접근할 경우 반드시 커널을 통해서 접근을 할 수 있습니다.
- 시스템 콜: 유저 모드에서 하드웨어 자원에 접근하는 상황이 있을 때 사용 되는 명령어이며 시스템 콜을 사용하게 되면 유저 모드에서 커널 모드로 변경된 후 하드웨어 자원에 접근되게 됩니다.
- 이렇게 유저 모드와 커널 모드를 나눈 이유는 특정 Application에 의해 하드웨어 자원이 손상되지 않기 위함입니다. 만약에 여러 개의 Application이 있는 상태에서 특정 Application에 의해 하드웨어 자원이 손상될 경우 해당 컴퓨팅 하드웨어 자원을 사용하고 있는 모든 Application이 영향을 받기위 이러한 피해를 방지하기 위함으로 모드가 나뉘어졌습니다.
- 그림 참고 링크: https://minnie.tuhs.org/CompArch/Lectures/week07.html

**인터럽트란 무엇이며 인터럽트와 시스템 콜의 차이점에 대해서 설명해주세요.**

- 인터럽트란 CPU가 현재 실행 중인 작업을 멈추고 어떠한 작업을 처리해야 하는 메커니즘을 말합니다.
- 인터럽트란 하드웨어 인터럽트와 소프트웨어 인터럽트 둘 다 존재합니다. 먼저 시스템 콜과 인터럽트 둘 다 커널 모드로 변경하여 하드웨어에 접근한다는 공통점이 있습니다. 하지만 시스템 콜은 명시적으로 이벤트가 발생하며 인터럽트는 비동기적인 이벤트가 발생한다는 차이점이 있으며 인터럽트는 어떠한 예외 상황을 처리하기 위한 메커니즘이라는 차이점이 있습니다. 실제로 시스템 콜이 내부적으로 처리 되는 과정에서 인터럽트가 동작 되기에 인터럽트에 시스템 콜이 포함된다는 점이 있습니다.
    - 하드웨어 인터럽트: 하드웨어 장치에서 인터럽트를 발생시키는 것
    - 소프트웨어 인터럽트: 소프트웨어 프로그램에 의해서 인터럽트를 발생시키는 것

**멀티프로세싱 시스템에서 스케줄링이 중요한 이유는 무엇인가요?**

- 성능 최적화를 위함입니다. 예를 들어서 유튜브로 노래를 들으면서 네이버에서 옷을 사려고 쇼핑을 할 때 스케줄링 성능이 좋지 않다면 유튜브에서 노래가 나왔다가 끊긴 상태에서 쇼핑을 하며 반대로 유튜브에서 노래는 나오는데 쇼핑을 할 수 없는 상황이 발생합니다.

**CPU 스케줄링 알고리즘의 종류와 특징은?(라운드 로빈, 우선순위 스케줄링, 멀티 레벨 큐)**

- 먼저 CPU 스케줄링 알고리즘에 앞서 알아야 할 용어들이 있습니다. 용어는 아래 정리 드리며 이러한 아래 용어의 값들로 인해 스케줄링 알고리즘의 성능이 결정됩니다.
    - Turnaround Time(반환 시간): 처음 스케줄링 이후 완료까지 걸리는 전체 시간으로 사용자 입장에서 전체 작업이 완료되어 결과를 받을 때까지의 시간입니다.
    - Response Time(응답 시간): 사용자 입장에서 요청을 보냈을 때 처음으로 반응(실제로 실행) 되는 시간입니다.
    - Fairness(형평성): 얼마나 균등(균일)하게 작업이 처리 되는지를 결정하는 지표로 사용자 입장에서 특정 작업이 너무 오래 될 경우 나머지 작업을 오래 기다리게 될 수 있는 확인하는 지표입니다.
    - Throughput(처리율): 얼마나 많은 작업을 처리할 수 있는지 확인하는 지표입니다.
    - DeadLine(마감 시간): 작업이 반드시 끝나야 하는 시간입니다.
- FIFO Scheduling Algorithm
    - 먼저 도착한 프로세스를 먼저 처리하는 알고리즘 기법입니다.
    - 작업 시간이 긴 프로세스가 먼저 도착하여 스케줄링이 되는 경우 나머지 프로세스가 늦게 처리 되는 단점이 있는 알고리즘입니다.
- Priority Scheduling
    - 각 프로세스에 우선순위를 부여하고 우선순위가 높은 프로세스부터 처리하는 스케줄링 알고리즘입니다.
    - 하나의 예로 **Shortest Job First 알고리즘 기법이 있는데 해당 기법은 실행시간이 적은 Job에 대해서 높은 우선순위를 부여하는 알고리즘입니다.**
    - 하지만 우선순위를 부여할 때 첫 스케줄링이 될 때를 기준으로 지정하기에 실행시간이 늦은  Job이 먼저 도착한다면 여전히 실행시간이 긴 Job이 오래 처리될 수 있다는 단점이 있습니다.
        - 이러한 단점을 해결하기 위해 STCF(Shortest Time-to Completion First) 알고리즘 기법이 나왔는데, 위와 동일한 상황에서 늦게 도착한 Job의 실행 시간이 더 짧을 경우 현재 실행 중인 Job을 중지시키고 실행시간이 긴 Job을 먼저 실행시기킵니다. 이에 따라서 Context Switching이 발생할 수 있습니다.
- **Round-Robin**
    - 프로세스가 처리해야 할 작업을 어떠한 시간 간격 만큼 잘라서 처리하는 스케줄링 알고리즘입니다. 그렇기에 실행시간이 짧던, 길던 모든 Job은 동일한 스케줄링 시간을 갖게 됩니다.
    - 라운드 로빈 알고리즘은 평균 응답 시간(사용자의 요청에 따른 반응 시간)은 빨라질 수 있지만 전체 프로세스가 스케줄링 되어 완료되는 시간인 평균 반환 시간은 늘어날 수 있다는 단점이 있습니다. 또한 이 부분에서 알 수 있듯이 평균 반환 시간과 평균 응답 시간은 반비례 관계로 Trade-off 관계에 있다는 것을 알 수 있습니다.
- **MLFQ(Multi Level Feedback Queue)**
    - 우선순위를 갖는 여러 개의 큐에 실행 되어야 할 Job들이 존재하여 스케줄링 되는 알고리즘 기법입니다. 일반적으로 사용 되는 규칙은 아래와 같습니다. 해당 기법은 응답 시간과 반환 시간의 반비례 관계를 최적화한 알고리즘입니다.
        - 규칙1: 우선순위가 "A(프로세스) > B(프로세스)"일 경우(같은 큐에 위치할 경우) A 실행
        - 규칙2: A와 B의 우선순위가 같을 경우 먼저 도착(요청)한 순서로 time slice만큼 각각 일정 시간 수행
        - 규칙3: 새로운 job(프로세스)가 도착할 경우 가장 높은 우선순위 부여
        - 규칙4: time slice 만큼 작업을 실행한 job은 우선순위가 감소
        - 규칙5: 특정 시간 동안 time slice에 대한 작업을 진행했는데 너무 오래 되는 경우 우선순위를 낮춤
    - 참고 링크: https://pawoo0211.tistory.com/63

**컨텍스트 스위칭이란 무엇이며, 컨텍스트 스위칭에 따라 오버헤드가 발생하는 이유가 무엇인가요?**

- Context Switching이란 CPU가 현재 실행중인 프로세스의 Context(프로세스 정보)를 PCB에 저장하고 다음 실행할 프로세스에 대한 PCB를 이용하여 CPU에 불러오는 것을 말합니다.
    - Context Save (컨텍스트 저장): 현재 실행 중인 프로세스를 저장하는 것
    - Context Load (컨텍스트 로드): 다음에 실행할 프로세스를 로딩하는 것
- 컨텍스트 스위칭에 따라서 오버헤드가 발생하는 이유
    - 현재 프로세스를 저정하고 다음 프로세스를 불러오는 것에 시간이 소요됩니다.
    - 다음 프로세스를 어떤 것을 불러올지에 대해서 CPU 연산이 발생하여 시간이 소요됩니다.
- 멀티 프로세스와 멀티 스레드 간에서도 Context Switching이 일어나지만 이에 대한 오버헤드는 멀티 프로세스가 더 큽니다.

**프로세스와 스레드의 차이점은 무엇인가?**

- Process
    - 프로세스란 CPU를 할당 받고 실제 수행되는 프로그램을 의미합니다.
    - 프로세스는 자신만의 고유한 메모리를 가지고 있습니다.
    - 각각의 프로세스는 “Code”, ”Data”, “Stack”, “Heap” 영역을 가지고 있습니다.
    - 프로세스는 프로세스들끼리 자원을 공유하지 않습니다.
        - 하지만 프로세스간의 통신을 이용 할 경우 접근이 가능합니다.
- Thread
    - 쓰레드란 프로세스 내에서의 실행되는 흐름의 단위입니다.
    - 하나의 프로세스는 최소 1개 이상의 쓰레드를 가지고 있습니다.
    - 각각의 쓰레드는 자신만의 **“Stack”**을 가지며 **“Code”**, **“Data”**, **“Heap”** 영역은 프로세스 내에서 쓰레드들끼리 공유합니다.
    - 쓰레드는 쓰레드들끼리 자원을 공유합니다.

**PCB(Process Control Block)란 무엇이며, 어떤 정보를 포함하나요?**

- PCB는 프로세스의 상태 및 자원 정보를 가지고 있는 데이터 구조를 의미합니다.
- PCB에 대한 정보는 아래와 같습니다.
    - 프로세스 식별 정보
    - 프로세스 상태
    - 프로세스 카운터: 프로세스가 어디에서 중단 되었는지 알 수 있는 주소
    - CPU 레지스터
    - 등등…
- 결론적으로 이러한 PCB를 통해서 프로세스를 관리하고 프로세스의 상태를 저장하며 프로세스가 사용하는 자원을 관리하고 추적할 수 있습니다.
- 참고 링크: https://pawoo0211.tistory.com/61

**프로세스 주소 공간이란 무엇이며, 프로세스마다 고유한 주소 공간을 가지는 이유는?**

- 프로세스 주소 공간은 각 프로세스가 사용하는 가상 메모리 영역을 말합니다. 해당 메모리 영역은 코드, 데이터, 힙, 스택으로 나뉘어집니다.
- 프로세스마다 고유한 주소 공간을 가지는 이유는 아래와 같습니다.
    1. 프로세스의 무분별한 메모리 접근에 의해서 하드웨어 자원이 망가질 경우 다른 프로세스에 영향이 갈 수 있기 때문입니다.
    2. 실제로 사용 가능한 메모리 공간을 찾기 위함입니다.
- 참고 링크: https://pawoo0211.tistory.com/52

**프로세스 상태 전이(Process State Transition)를 설명해보세요.**

- 프로세스 상태
    - 생성(Create): 프로세스 생성된 최초의 상태이며 디스크에 저장되어 있는 상태
    - 준비(Ready): 프로세스가 CPU를 사용할 준비가 된 상태
    - 실행(Running): 프로세스가 CPU에 스케줄링 되어 실행되고 있는 상태
    - 대기(Wating): 대기 상태 또는 I/O 입축력 또는 이벤트를 기다리는 상태
    - 종료(Terminated): 프로세스가 자신의 일을 끝내고 종료한 상태
- 프로세스 상태 전이
    - **Admit**
        - **설명**: 새로운 프로세스가 생성되어 **보조 기억 장치(디스크)**에서 **주 기억 장치(RAM)**로 로드되는 단계입니다.
        - **상태 전이**: 생성 → 준비(Ready)
    - **Dispatch**
        - **설명**: 준비 상태에 있는 프로세스 중 하나가 **CPU 스케줄러**에 의해 선택되어 CPU에서 실행되기 시작합니다.
        - **상태 전이**: 준비(Ready) → 실행(Running)
    - **Timeout**
        - **설명**: CPU 할당 시간이 만료된 프로세스가 실행 상태에서 준비 상태로 되돌아갑니다. 이는 주로 **선점형 스케줄링**에서 발생하며, 다른 프로세스에게 CPU를 할당하기 위해 필요한 전이입니다.
        - **상태 전이**: 실행(Running) → 준비(Ready)
    - **Block**
        - **설명**: 실행 중인 프로세스가 **입출력(I/O) 작업을 요청**하면 CPU를 더 이상 사용할 수 없게 되며, I/O 처리를 기다리는 **대기 상태**로 전이됩니다.
        - **상태 전이**: 실행(Running) → 대기(Waiting)
        - **추가 설명**: 대기 상태에서는 CPU가 아니라 별도의 **I/O 디바이스**가 입출력 처리를 담당합니다.
    - **Wakeup**
        - **설명**: 대기 상태에 있는 프로세스가 **I/O 작업을 마치고** 다시 준비 상태로 돌아오는 단계입니다.
        - **상태 전이**: 대기(Waiting) → 준비(Ready)
    - **Completion**
        - **설명**: 실행 중인 프로세스가 자신의 작업을 모두 완료하여 **종료 상태**로 전이되며, 할당된 자원을 반납합니다.
        - **상태 전이**: 실행(Running) → 종료(Terminated)

**프로세스 간 통신(IPC: Interprocess Communication) 방법에는 무엇이 있나요? (파이프, 메시지 큐, 공유 메모리 등)**

- 프로세스는 자신이 가지고 있는 메모리가 있으며 해당 메모리는 프로세스간의 공유를 하지 않습니다. 그렇지만 다른 프로세스의 메모리에 접근할 필요성이 있는 경우 IPC를 이용합니다.
- 공유 메모리: 프로세스간에 공유하는 메모리를 사용하는 방식입니다. 모든 프로세스가 읽고 쓸 수 있으며 가장 데이터 교환 속도가 빠릅니다. 대신에 동시성 문제가 발생할 수 있기에 동기화 처리가 진행되어야 합니다.
- 파이프: 한 프로세스에서 다른 프로세스로 데이터를 전송하는 방식입니다. 데이터 전송 방향이 단방향이기에 양쪽 프로세스에서 통신이 필요할 경우 2개의 파이프 라인을 설치해야 합니다. 주로 부모 프로세스와 자식 프로세스간의 통신을 진행할 때 사용합니다.
- 메세지 큐: 송신 프로세스가 메세지 큐에 데이터를 넣고 수신 프로세스가 메세지 큐에서 데이터를 읽어오는 방식입니다.

**멀티스레드(Multithreading)의 장점과 단점은 무엇인가요?**

- 먼저 멀티쓰레딩 프로그래밍이란 하나의 프로세스 안에 여러 개의 쓰레드가 존재함으로써 해당 쓰레드들이 동기적 또는 비동기적, 병렬적으로 작업하는 것을 말합니다.
- 장점: 쓰레드의 특징 상 쓰레드들은 메모리를 공유할 수 있기에 어떠한 작업을 처리할 때 메모리 공간의 효율성이 증가합니다. 또한 컨텍스트 스위칭에 대한 오버헤드가 적기에 병렬 처리에 대해서 이점이 있습니다.
- 단점: 쓰레드의 특징 상 메모리를 공유하기에 데이터의 부정합이 발생할 수 있기에 동기화 처리가 필요합니다.
- JVM과 스프링에서의 프로세스 및 멀티 쓰레딩 관련
    - JVM: 운영체제에서 하나의 네이티브 프로세스로 관리, 운영체제는 JVM 전체를 하나의 단일 프로세스로 인식
    - 스프링: 스프링인 멀티 쓰레딩이기에 JVM이라는 하나의 프로세스에서 여러 멀티 쓰레드들이 존재하는 프로그램

**스레드 동기화(Thread Synchronization)가 중요한 이유는 무엇인가요?**

- 동시성 문제와 비슷하지만 스레드 동기화는 스레드의 흐름 제어에 초점을 맞춘 것이며 한 스레드가 작업을 진행중일 때 다른 스레드가 간섭하지 못하게 하는 것을 말합니다.
- 스레드 동기화가 중요한 이유
    - 스레드간의 동기화 처리가 되지 않는다면 스레드 간의 흐름 제어가 의도한 것과 변경되어 예상하지 못한 결과가 발생할 수 있습니다.
- 자바의 Synchronized 선언: 하나의 스레드만 접근할 수 있도록 lock을 걸어주는 기법

**동시성 문제란 무엇인가?**

- 동시성 문제란 분산 시스템, 또는 멀티 프로세스, 멀티 스레딩 시스템에서 어떠한 공유 자원에 대해서 쓰거나 읽을 때 데이터의 정합성이 맞지 않는 것을 말합니다. 결과적으로는 데이터 정합성 측면에서 차이점이 있습니다.
- Atomic 기법은 동시성을 처리하는 기법 중 하나이지만 쓰레드 동기화를 이용하여 처리하는 기법이 아닙니다. Atomic은 동기화를 처리할 때 흐름 제어 측면이 아닌 메모리 측면에서 값을 비교하는 방식입니다.

**교착 상태(Deadlock)란 무엇인가요? 교착 상태의 해결 방법을 설명해보세요.**

- 교착 상태란 두개 이상의 작업이 상대방이 끝나기만을 기다려 모든 작업이 기다리고만 있는 상태를 말합니다.
- 교착 상태 해결 방법
    1. Deadlock Prevention: 교착 상태는 4가지의 필요 조건이 충족할 때 발생하기에 4가지의 필요 조건 중 하나 이상을 제거하는 방법입니다.
        - 상호 배제 제거: 다수의 프로세스가 자원을 동시에 접근할 수 있도록 합니다.
        - 점유 대기 제거: 프로세스가 자원을 요청할 때 하나의 자원이 아닌 모든 자원에 대해서 한번에 요청하도록 강제합니다.
        - 비선점 제거: 점유하고 있는 자원을 강제로 회수합니다.
        - 환형 대기 제거: 자원 요청에 대하여 순서성을 부여합니다.
    2. Deadlock Avoidance: 데드락 발생 가능성을 계속 검새해서 데드락 발생 가능성이 있다면 회피하는 방식입니다. 데드락이 발생하지 않을 상태를 safe state, 데드락이 발생할 수 있는 상태를 unsafe state로 지정하여 safe sate에서 unsafe state로 변경되는 경우 원인을 찾아 다시 safe sate로 변경하는 방법입니다.
    3. Deadlock Detection and Recovery: 지속해서 데드 락을 탐지하고 데드락이 발생할 경우 복구하는 방법입니다. 데드락이 발견 되면 특정 프로세스를 종료 시켜 데드락을 해소시킨 후 종료된 프로세스가 가진 자원을 강제로 회수하여 다른 프로세스에게 부여하는 방법입니다.

**임계 구역(Critical Section)이란 무엇이며, 이를 해결하는 방법은 무엇인가요?**

- 임계 영역이란 경쟁 상태를 야기하는 실제 영역 또는 실제 코드 부분(묶음)을 말합니다.
    - 경쟁 상태란 2개 이상의 쓰레드가 공유 자원에 동시에 접근하는 상황을 말합니다.
- 임계 영역 해결 방법
    - 상호 배제(Mutual Exclusion) 또는 동기화(Synchronization)를 이용합니다.
    - 상호 배제와 동기화의 차이점은 상호 배제는 순서를 보장하지 않지만 동기화는 상호배제를 보장하는 것 뿐 아니라 순서성 또한 보장합니다.

**상호 배제(Mutual Exclusion)란 무엇인가요?**

- 상호 배제란 임계 영역을 보장하는 방법으로 lock과 unlock을 사용하는 방식입니다.
- 상호 배제에 대한 실제 동작 방식은 아래와 같습니다.
    - https://pawoo0211.tistory.com/65
    - sleep lock: lock이 될 경우 A 쓰레드가 대기 상태에 빠지며 unlock이 되면 쓰레드가 깨어나 lock을 걸고 공유 자원에 접근하는 방식, spin lock은 polling 방식이기에 계속해서 컴퓨팅 리소스가 발생한다는 단점이 있음 → Synchronization

**뮤텍스(Mutex)와 세마포어(Semaphore)의 차이점은 무엇인가요?**

- 뮤텍스: 오직 하나의 스레드만이 임계 영역에 들어갈 수 있으며 순서성이 보장되지 않는 Locking 기법입니다. 락을 획득한 스레드만이 해당 락을 해제할 수 있습니다. 뮤텍스는 0, 1로 이루어진 세마포어로 볼 수 있습니다.
- 세마포어: 2개 이상의 스레드에 대해서 임계 영역에 들어갈 수 있도록 보장해주며 순서성이 보장되지 않는  Locking 기법입니다. 세마포어를 소유하지 않는 스레드가 세마포어의 값을 변경할 수 있습니다.

**스핀락(Spinlock)과 같은 동기화 기법은 언제 사용되나요?**

- 대기 시간이 더 짧은 경우에 사용합니다. 스핀 락은 폴링 방식으로 계속해서 락이 해제 되는 것을 확인하기에 CPU 사용량이 많아 대기 시간이 긴 경우에는 적합하지 않습니다.
- 반대로 대기 시간이 긴 경우에는 슬립 락을 사용합니다. 쓰레드가 공유 자원에 접근한 후 락이 걸려 있으면 대기하는 방식이기에 대기 시간이 긴 경우 슬립 락을 사용합니다.

**Readers-Writers, 생산자-소비자 문제와 식사하는 철학자 문제에 대해서 설명해주세요.**

- Readers-Writers 문제: 다수의 독자와 저자가 데이터를 읽고 쓸 때 동시성이 발생하는 문제 상황입니다.
- 생산자-소비자 문제: 생산자와 소비자가 공유 버퍼를 사용하는 상황에서 동시성 문제가 발생하는 상황을 말합니다.
- 식사하는 철학자 문제: 5명의 철학자가 식사를 할 때 공유 자원인 포크를 사용하는 경우 교착 상태가 발생하는 문제 상황을 말합니다.
- https://pawoo0211.tistory.com/67

**조건 변수(condition variable)란 무엇인가요?**

- 조건 변수란 다중 스레드 프로그래밍에서 스레드간의 동기화 처리를 진행할 때 사용되는 변수로 특정 조건이 충족될 때까지 스레드를 대기 상태로 만들거나 대기 중인 스레드를 깨워주는 데에 사용 되는 것입니다.

**메모리 계층 구조에 대해서 설명해주세요.**
- 메모리 계층 구조란 메모리를 필요에 따라 여러 가지 종류로 나누어 둠을 의미합니다.
- 메모리 계층 구조
    - Register → L1 Cache → L2 Cache → Main memory → Disks → Remote secondary storage
    - ← 접근 속도는 빠르지만 저장 용량이 적음 / 접근 속도는 느리지만 저장 용량이 큼 →
- 레지스터(Register)
    - CPU 내부에 있는 매우 빠른 메모리로, 프로그램에서 즉시 사용해야 하는 데이터(예: 연산 중인 변수)를 저장합니다. 용량은 매우 작지만, 접근 속도가 가장 빠릅니다.
- 캐시 메모리(L1, L2 Cache)
    - CPU와 메인 메모리 사이에 위치하며, CPU가 자주 접근하는 데이터를 저장해 메인 메모리에 접근할 때의 대기 시간을 줄이는 역할을 하는 메모리입니다. 캐시는 일반적으로 L1, L2, L3로 나뉘며, L1이 가장 빠르고, L3가 가장 느리고 용량이 큽니다.
- 메인 메모리
    - CPU가 직접 데이터를 읽고 쓸 수 있는 대용량 메모리로, 실행 중인 프로그램과 그 데이터를 저장합니다. 휘발성 메모리 영역으로 전원 공급이 꺼지면 저장 되어 있는 데이터가 사라지는 특성을 가지고 있습니다.
- 디스크
    - 프로그램과 데이터 파일을 저장하며, 메인 메모리에 비해 접근 속도가 매우 느리지만, 저장 용량은 큽니다. 영구적인 데이터 저장 장치로, 시스템이 꺼져도 데이터를 유지하는 비 휘발성 특성을 가진 메모리 영역입니다.
- 보조 저장 장치 및 원격 저장소
    - USB 드라이브나 네트워크 스토리지(NAS)와 같이 장기 보관용으로 사용됩니다. 접근 속도가 가장 느리지만, 용량은 매우 큽니다.

**메모리에서 스택, 힙, 코드, 데이터 영역에 대해서 설명해주세요.**
- 코드 영역: 실행할 프로그램의 코드를 저장하는 영역
- 데이터 영역: 전역 변수와 정적 변수를 저장하는 영역
- 힙 영역: 동적 메모리 할당을 위한 영역, 동적으로 메모리 영역이 할당 되기에 메모리의 크기가 고정적이지 않고 동적입니다. 이 때 메모리 영역이 확장될 때 낮은 메모리 주소에서 높은 메모리 주소로 확장됩니다.
- 스택 영역: 지역 변수와 함수 호출 정보를 저장하는 영역, 스택 영역 또한 메모리 공간이 고정적이지 않고 동적이며 힙 영역과는 반대로 높은 메모리 주소에서 낮은 메모리 주소 방향으로 메모리가 확장됩니다. 각각의 스레드는 별도의 스택을 고유하게 가지고 있습니다.
- 참고 그림: https://bo5mi.tistory.com/159

**가상 메모리(Virtual Memory)란 무엇인가요?**
- 프로세스가 가지는 고유한 가상의 메모리를 의미합니다.  멀티 프로세싱이 되는 현대화 컴퓨팅에서 실제 물리 메모리에 접근할 때 무분별한 접근을 막기 위해 탄생한 개념입니다.
- https://pawoo0211.tistory.com/52

**페이지 테이블(Page Table)이란 무엇이며, 그 역할을 설명해보세요.**
- 페이지 테이블이란 프로세스의 가상 메모리를 실제 물리 메모리 주소와 매핑 하는 자료구조를 의미합니다. 페이지 테이블은 각각의 프로세스가 가지고 있으며 Page를 Page frame으로 변환 시켜 가상 메모리를 물리 메모리로 변환합니다.
- 페이지(Page)란 가상 메모리의 각 영역이 고정된 크기로 분할 된 것을 말합니다.
- 페이지 프레임(Page frame)이란 물리 메모리 영역을 고정된 크기로 분할 된 것을 말합니다.

**페이지 교체 알고리즘(FIFO, LRU, Optimal 등)의 차이점을 설명하세요.**
- 페이지 교체 알고리즘은 페이지 폴트가 발생했을 때, 어떤 페이지를 물리 메모리에서 제거할지를 결정하는 방법입니다.
- FIFO (First-In, First-Out): 페이지가 메모리에 로드 된 순서에 따라 제거하는 방식으로 먼저 메모리에 로드 된 페이지가 제거 되는 방식입니다.
- LRU (Least Recently Used): 가장 오랫동안 사용되지 않는 페이지를 먼저 제거하는 방식으로 페이지의 사용기록을 관리해야 합니다.
- Optimal (Optimal Page Replacement): 앞으로 가장 오랫동안 사용되지 않을 페이지를 제거하는 방식으로 페이지를 미리 예측해서 제거하는 방식입니다. 실제로 사용할 수 있는 알고리즘이 아닙니다.

**페이지 폴트(Page Fault)란 무엇이며, 어떻게 처리되나요?**
- 페이지 폴트란 요청한 가상 메모리의 주소가 물리 메모리 주소에 존재하지 않을 때 발생하는 이벤트입니다. 결국에는 필요한 데이터를 못찾을 때 발생하는 현상입니다.
- 이에 대한 처리 방법은 디스크에 해당 데이터를 메모리에 로드 하는 방식으로 처리됩니다.
    1. 프로세스가 요청한 페이지가 메모리에 없음을 확인
    2. 디스크에서 요청한 페이지 로드
    3. 메모리가 가득 찬 경우, 사용하지 않는 페이지를 제거하고 새로운 페이지를 적재
    4. 페이지 테이블 업데이트(이후 해당 페이지를 다시 요청할 수 있으므로)
    5. 프로그램 실행 재개

**TLB(Translation Lookaside Buffer)의 역할은 무엇인가요?**
- 가상 메모리 주소에 대한 물리 메모리 주소를 변환 캐시입니다.
- CPU에서 메인 메모리로 접근할 때 아래와 같은 두 번의 작업이 필요한데 TLB에 값이 있는 경우 1번의 조회만으로 가능하게 해줍니다.
    1. 페이지 테이블 조회
    2. 페이지 테이블에서 조회한 실제 메모리 주소를 통해 접근
- [https://velog.io/@becooq81/운영체제-TLB](https://velog.io/@becooq81/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-TLB)

**스와핑(Swapping)이란 무엇이며, 언제 발생하나요?**
- 스와핑이란 메모리의 여유 공간이 부족할 때 메모리 공간을 사용하는 경우, 현재 실행 중인 프로세스를 디스크로 보내고(**Swap out**) 새로 요청한 프로세스의 데이터를 메모리에 할당하는 것(**Swap in**)을 말합니다.
- 스와핑을 사용하게 되면 현재 사용하고 있는 물리 메모리보다 더 큰 데이터들을 사용할 수 있게 됩니다. 메모리는 저장 공간이 작지만 디스크는 저장 공간이 크기에 현재 사용하고 있는 데이터는 메모리에 위치시키고 사용하지 않는 데이터는 디스크에 위치시켜 이러한 연속적인 동작으로 메모리 사용량이 큰 프로그램을 사용할 수 있게 됩니다.

**세그멘테이션(Segmentation)과 페이징(Paging)의 차이점은 무엇인가요?**

- 페이징: 페이징은 물리 메모리 구조를 고정된 크기로 나누는 방식이며 이에 따라 연속 메모리 할당의 문제인 내부 단편화가 발생합니다.
- 세그멘테이션: 세그멘테이션은 코드, 데이터, 힙, 스택 영역에 따라서 메모리를 나누는 방식으로 비연속 메모리 할당 방식입니다. 비연속 메모리 할당에 따른 내부 단편화가 발생합니다.
- 세그멘테이션이 메모리 효율성이 높지만 이에 따른 메모리 관리 복잡성 또한 높습니다.

**메모리 단편화(Fragmentation)란 무엇이며, 내부 단편화와 외부 단편화의 차이점은 무엇인가요?**
- 메모리 단편화란 사용 가능한 메모리 공간이 여러 개의 조각으로  나뉘어져 사용 가능한 상태임에도, 각 조각의 크기가 너무 작거나 연속적이지 않고 흩어져 있어서 사용하기 어려운 상태를 말합니다. 주로 페이징에서 발생합니다.
- 내부 단편화란 실제로 사용할 메모리 공간보다 할당 받은 메모리 공간이 커서 불필요하게 메모리 공간이 남는 단편화를 말합니다.
- 외부 단편화란 실제로 사용 가능한 메모리 공간이 너무 흩어져 있어 모두 다 합치면 충분한 메모리가 됨에도 연속된 메모리 할당이 불가능한 단편화 상태를 말합니다. 주로 세그멘테이션에서 발생합니다.

**페이지 크기(Page Size)가 메모리 관리에 미치는 영향은 무엇인가요?**
- 페이지의 크기는 가상 메모리에서 페이지의 크기와 물리 메모리에서 페이지 프레임의 크기를 결정하는 요소입니다.
- 페이지 크기가 너무 큰 경우 내부 단편화가 증가하며 디스크에서 메모리로 데이터를 불러올 때 사용하지 않는 데이터까지 불러올 수 있어 디스크 I/O 측면에서 비효율적입니다.
- 페이지 크기가 너무 작은 경우 외부 단편화가 감소하며 페이지가 더 많아지기에 페이지 테이블의 크기가 커질 수 있습니다. 이렇게 페이지 테이블이 커지면 캐시 미스율이 증가할 수 있어 캐싱 측면에서는 효율이 떨어질 수 있습니다.

**SSD와 HDD의 차이점은 무엇인가요?**
- SSD와 HDD 모두 데이터를 저장하는 저장 장치입니다. 다만 데이터를 저장하는 방식과 저장을 할 때의 성능적인 차이점이 존재합니다.
- SSD(Solid State Drive): 회전하는 플래터 위에 데이터를 저장하고, 헤드가 플래터를 따라 움직이며 데이터를 읽고 씁니다. 상대적으로 속도가 느립니다.
- 하드디스크(HDD): AND 플래시 메모리에 데이터를 저장하는 반도체 기반 장치로, 데이터가 전기적 신호로 저장되고 읽힙니다. 따라서 HDD에 비해 빠르고 조용하게 동작합니다.

**캐시(Caching)는 운영 체제에서 어떤 역할을 하며, 성능 향상에 어떻게 기여하는가요?**
- 캐시가 운영체제에서 하는 역할
    1. 데이터 접근 시간 단축: CPU에서 자주 사용하는 데이터에 대해서 메모리와 디스크까지 접근하지 않고 캐시에서 조회할 시 조회 속도 향상
    2. CPU와 메모리 간 병목 현상 해소: CPU에서 메모리로 데이터를 조회하는 상황에서 대기가 발생할 수 있는데 이러한 대기가 많아지면 병목 현상이 발생할 수 있음, 이러한 부분을 캐시를 통해 방지

**캐시 히트(Cache Hit)와 캐시 미스(Cache Miss)란 무엇이며, 캐시 히트율(Cache Hit Rate)은 어떻게 측정되는가요?**
- Cache Hit: CPU에서 접근하려는 데이터가 캐시에 있는 경우
- Cache Miss: CPU에서 접근하려는 데이터가 캐시에 없는 경우
- Cache Hit Rate:  ****Cache Hit / 총 접근 횟수

**캐시의 공간적 지역성과 시간적 지역성에 대해서 설명해주세요**
- 공간적 지역성(Temporal locality): 한번 접근한 데이터는 미래에 다시 접근할 가능성이 높은 특성
- 시간적 지역성(Spatial locality): 어떠한 데이터에 접근했을 때 접근 된 데이터의 주변 데이터도 다음에 접근할 가능성이 높은 특성

**버퍼 캐시(Buffer Cache)와 페이지 캐시(Page Cache)의 차이점은 무엇이며, 파일 시스템에서 각각의 역할은 무엇인가요?**
- 파일: 운영체제에서의 논리적인 데이터 단위
- 블록: 저장 장치에서 저장된 데이터의 물리적인 단위
- 버퍼 캐시: 블록 디바이스가 가지고 있는 블록 자체에 대한 캐시입니다. 커널이 데이터를 읽기 위해서는 디바이스의 특정 블록에 접근해야 하는데 이 대 블록에 대한 내용을 버퍼 캐시에 담아두고 동일한 블록에 접근하는 경우 블록 디바이스에 접근하는 것이 아닌 먼저 버퍼 캐시에 접근합니다.
- 페이지 캐시: 파일 I/O 성능 향상을 위해 사용하는 페이지 캐시입니다. 한 번 읽은 파일의 내용을 페이지 캐시에 저장했다가 동일한 파일에 대한 접근을 진행할 때 디스크에서 읽지 않고 먼저 페이지 캐시에 데이터를 조회합니다.

**파일 시스템이란 무엇인가요?**
- 파일 시스템이란 물리적 저장소인 디스크를 추상화(가상화)한 것입니다.  기존의 디스크는 연속적인 블록의 집합으로 구성되어 있는데 이를 논리적인 파일과 디렉터리 구조의 집합으로 추상화 한 것이 파일 시스템입니다 .

**파일 시스템에서 inode의 역할은 무엇인가요?**
- 파일 시스템에서 inode는 파일과 디렉터리에 대한 메타데이터를 저장하는 구조체로 운영체제가 파일 시스템을 관리하고 파일 및 디렉터리에 접근할 때 참조하는 구조체입니다.
- inode 역할
    1. 파일 및 디렉터리에 대한 모든 정보 저장
    2. 파일 데이터가 저장된 실제 데이터 블록의 위치를 가리키는 포인터를 가지고 있음
    - A(File Name) → inode → file(data file)

**파일 디스크립터(File Descriptor)는 무엇인가요?**
- 파일 디스크립터란 파일에 대한 정수 값을 의미합니다. 프로세스는 해당 정수 값을 이용하여 파일에 접근하게 됩니다.
    - 일반적으로 자주 사용하는 입출력에 대해서는 이미 지정되어 있는 파일 디스크립터 값이 존재합니다.
    1. stdin(표준입력): 0
    2. stdout(표준출력): 1
    3. stderr(표준에러): 2
- 파일을 읽거나 쓸 때 먼저 파일을 열거나 생성하게 되는데 이 때 운영체제로부터 파일 디스크립터 값을 할당받게 됩니다. 그 후 해당 파일 디스크립터에 대해서 접근하여 파일을 쓰며 작업이 완료되면 해당 파일 디스크립터 값을 닫아줍니다.
```jsx
// 파일 열기: "file.txt"를 쓰기 모드로 열기
int fd = open("file.txt", O_WRONLY);

// 파일 쓰기
write(fd, text, strlen(text));

// 파일 닫기
close(fd)
```
- 파일 디스크립터는 파일 디스크립터 테이블에서 관리가 됩니다. 이 때 각각의 프로세스는 자신만의 파일 디스크립터 테이블을 가지고 있습니다.
    - 전체적인 파일 관리: 파일 디스크립터 테이블 → 파일 테이블 → inode 테이블 → 파일 시스템
    - https://m.blog.naver.com/songblue61/221391888403

**파일 시스템에서 링크(link)란 무엇이며, 하드 링크와 심볼릭 링크의 차이점에 대해서 설명해주세요**
- 파일 시스템에서 링크란 inode를 통해서 파일 또는 디렉터리에서 실제 데이터 블록에 대한 참조를 진행하는 메커니즘입니다.
- 소프트 링크: 파일 A → inode → File(실제 데이터 File)
- 하드 링크: 파일 B → inode → 파일 A

**저널링 파일 시스템(Journaling File System)이란 무엇인가요?**
- 저널링 파일 시스템이란 주 파일 시스템에 변경사항을 반영(commit)하기 전에, **저널**(주로 파일 시스템의 지정된 영역 안의 원형 로그)안에 생성되는 변경사항을 반영하고 변경 사항을 파일 시스템에 반영하는 것을 말합니다. 일종의 데이터베이스 트랜잭션과 같은 원리입니다.
- 이러한 데이터 저널링 과정은 아래와 같습니다.
    1. Journal Write: 데이터 변경 사항을 영구 저장하기 전에 임시 저장소(저널)에 기록하는 단계입니다.
    2. Journal Commit: 임시 저장소에 기록된 데이터 변경 사항을 실제 데이터 저장소에 반영하는 단계로, 이 단계에서 데이터는 아직 최종적으로 저장되지 않았습니다.
    3. Checkpoint: 데이터 변경 사항을 최종적으로 저장하고 데이터 저장소에 반영하는 단계입니다.

**디스크 스케줄링이 필요한 이유와 다양한 알고리즘의 장단점은 무엇인가요? (FCFS, SSTF, SCAN 등)**
- 디스크 스케줄링이 필요한 이유는 실제로 디스크에 데이터를 쓰거나 읽을 때는 헤드가 여러 트랙으로 이동하면서 진행됩니다. 그런데 이 때 디스크 스케줄링에 따라서 디스크 헤드의 물리적인 이동 순서를 최적화 하여 디스크 액세스 시간을 최적화 할 수 있기에 디스크 스케줄링이 필요합니다.
- FCFS: 요청 순서에 따라서 처리하는 방식
    - 장점: 작업 처리에 대한 공정성을 보장합니다.
    - 단점: 요청 순서에 대한 트랙 거리가 멀 경우 작업 완료에 대한 비효율성이 증가합니다.
- SSTF: 현재 헤드 위치에서 가장 가까운 요청을 먼저 처리하는 방식
    - 장점: 헤드 이동 거리가 짧기에 평균 접근 시간을 최소화 할 수 있습니다.
    - 단점: 인접한 트랙의 요청 처리를 먼저 하기에 거리가 먼 요청은 처리가 안될 수 있는 기아 현상이 발생할 수 있습니다.
- SCAN: 한 방향으로 모든 요청을 처리 한 후 역 방향으로 다시 요청을 처리하는 방식
    - 장점: SSTF에서 발생할 수 있는 기아 현상을 어느정도 해결하면서 공정성을 보장합니다.
    - 단점: 헤드가 일방향으로 끝가지 탐색을 진행하기에 전체 접근 시간이 길어질 수 있습니다.
- [https://ohaengsa.tistory.com/entry/운영체제-디스크-스케줄링Disk-Scheduling](https://ohaengsa.tistory.com/entry/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EB%94%94%EC%8A%A4%ED%81%AC-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81Disk-Scheduling)

**운영체제에서 마운트란 무엇이며, 운영체제에서 어떻게 동작되는가**
- 운영체제에서 마운트란 실제 물리 장비인 하드웨어 장치들을 리눅스 또는 다른 운영체제에 실질적으로 연결 시키는 것을 말합니다.
    - 예를 들어서 USB 드라이브가 `/mnt/usb`라는 디렉터리에 마운트되면, 사용자는 이 경로를 통해 USB 드라이브의 파일에 접근할 수 있습니다.
- 운영체제에서의 마운트 동작 과정
    1. 장치 감지: 운영 체제에서 새로운 저장 장치가 연결될 때 이를 감지합니다.
    2. 파일 시스템 확인: 장치의 파일 시스템 유형을 확인합니다.
    3. 마운트 포인트 설정: 사용자가 설정한 디렉터리에 장치의 파일 시스템을 연결합니다.
    

**동기와 비동기 그리고 병렬성에 대한 차이점에 대해서 설명해주세요.**
- 동기란 작업이 진행될 때 요청에 따른 응답이 완료 된 후 다음 작업이 진행되는 것을 말합니다.
- 비동기란 작업이 진행될 때 요청에 따른 응답이 완료 되기 전에 그 다음 작업이 진행되는 것을 말합니다.
- 병렬이란 작업이 진행될 때 2개 이상의 작업이 동시에 진행되는 것을 말합니다.

**CPU 개수가 증가할수록 시스템의 성능이 좋아지는 이유에 대해서 설명해주세요.**
- 멀티 프로세스, 멀티 스레드 상황에서 CPU가 한개 있을 경우 실제로 스케줄링 되는 것은 하나이기에 굉장히 빠른 컨텍스트 스위칭이 일어나면서 하나의 CPU로만 프로세스가 실행되게 됩니다. 컨텍스트 스위칭 과정에서 오버헤드가 발생하기에 CPU가 한개만 있을 경우 각각의 프로그램의 실행 또는 동작이 느려지게 됩니다. 이러한 상황에서 CPU가 증가하게 되면 동시에 처리할 수 있는 프로세스 및 스레드의 수가 줄어들기 때문에 CPU 개수가 증가하게 되면 시스템의 성능이 좋아질 수 있습니다.

**멀티코어 CPU 환경에서 자바의 병렬 처리 성능을 최적화하기 위해 코어 수와 스레드 수의 균형을 어떻게 맞춰야 하는가요?**
- 적정 스레드 개수 = 사용 가능한 코어의 개수 * 목표 CPU 사용률 * (1 + 대기시간/서비스시간)
    - 사용 가능한 코어의 수: CPU 코어의 개수는 한번에 처리할 수 있는 병렬 연산의 개수이므로 컨텍스트 스위칭 비용이 들지 않음
    - 목표 사용률: CPU에사 자원을 얼마나 활용하는지에 대한 수치로 100%로 설정하는 것이 아닌 이보다 여유 있게 처리하는 것이 좋음
    - 대기 시간 / 서비스 시간: 대기 시간이란 스레드가 사용되지 않고 기다리는 시간을 의미하며 서비스 시간은 스레드의 요청에 대한 작업 시간을 의미 → 대기 시간이 길 수록 남는 스레드가 많기에 스레드의 개수를 더 많이 할당
- CPU 코어에 따른 스레드와 톰캣 스레드의 상관 관계
    - 톰캣의 스레드 처리는 하드웨어의 스레드 개수에 영향을 받습니다만, 하드웨어의 스레드 개수가 늘어난다고 해서 톰캣의 최대 멀티 스레드 개수는 늘어나지 않습니다. 톰캣에서 Max 스레드 값을 따로 설정해야 합니다.
    - [https://velog.io/@devty/CPU-Thread-TomCat의-상관관계-tfhf2w2q](https://velog.io/@devty/CPU-Thread-TomCat%EC%9D%98-%EC%83%81%EA%B4%80%EA%B4%80%EA%B3%84-tfhf2w2q)

**CPU 바운드(CPU-bound) 작업과 I/O 바운드(I/O-bound) 작업의 특성에 따라 병렬 처리 전략을 어떻게 달리 설정해야 하는가?**
- CPU 바운드(CPU-bound) 작업: CPU 기반의 연산이 많은 경우 CPU의 코어 개수와 밀접한 연관성이 있기에 “스레드 수 ≈ 코어 수 + 1” 수준으로 설정합니다.
- I/O 바운드(I/O-bound) 작업:

**JVM에서 Garbage Collection이 병렬 처리 성능에 미치는 영향은 무엇이며, 이를 최적화하기 위한 JVM 튜닝 방법은?**
1. GC가 병렬 처리 성능에 미치는 영향
- **스톱-더-월드(Stop-the-World)**: GC가 수행되는 동안 애플리케이션의 모든 스레드가 일시 중지됩니다. 그렇기에 해당 시간에 병목 현상이 발생할 수 있습니다.
- GC가 처리되는 과정에서 CPU 연산이 필요하기에 병렬 처리 시 이에 대한 영향을 받을 수 있습니다.
1. GC 최적화를 위한 JVM 튜닝 방법
- Parallel GC: GC 작업을 여러 스레드에서 병렬로 수행하여 GC 시간을 줄이는 방식
    - Parallel GC를 사용하더라도 Stop-the-World의 시간이 줄어들 뿐 쓰레드의 중단은 발생할 수 있음
- GC 스레드 개수 조절: **=n** 옵션을 사용하여 GC 작업을 병렬로 처리할 때 사용할 스레드의 개수를 조정하여 Application에서 처리하는 쓰레드의 개수와 GC에서 사용되는 쓰레드 개수를 분할하여 GC 시 Application에 영향을 가지 않도록 처리
